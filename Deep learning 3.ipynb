{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a7a83c1",
   "metadata": {},
   "source": [
    "#### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490e4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e957609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['Well done!',\n",
    " 'Good work',\n",
    " 'Great effort',\n",
    " 'nice work',\n",
    " 'Excellent!',\n",
    " 'Weak',\n",
    " 'Poor effort!',\n",
    " 'not good',\n",
    " 'poor work',\n",
    " 'Could have done better.']\n",
    "# define class labels\n",
    "labels = array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9003e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 1, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot('Hello how are you', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08d1525f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[41, 11],\n",
       " [30, 3],\n",
       " [1, 32],\n",
       " [35, 3],\n",
       " [8],\n",
       " [15],\n",
       " [6, 32],\n",
       " [14, 30],\n",
       " [6, 3],\n",
       " [32, 20, 11, 27]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "encoded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56384f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41, 11,  0,  0],\n",
       "       [30,  3,  0,  0],\n",
       "       [ 1, 32,  0,  0],\n",
       "       [35,  3,  0,  0],\n",
       "       [ 8,  0,  0,  0],\n",
       "       [15,  0,  0,  0],\n",
       "       [ 6, 32,  0,  0],\n",
       "       [14, 30,  0,  0],\n",
       "       [ 6,  3,  0,  0],\n",
       "       [32, 20, 11, 27]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d4f7815",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 3, input_length=max_length,name='emb'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51d7e754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " emb (Embedding)             (None, 4, 3)              150       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 12)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163\n",
      "Trainable params: 163\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bdc0be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bd6c12b580>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_docs, labels, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "793425d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.999999\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da7ed8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=model.get_layer('emb').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0414c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09815478, -0.04210135, -0.08211587], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07cd5f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0942912 , -0.06128442, -0.02740877], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38004297",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29cb9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2aadcf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  ... unixReviewTime   reviewTime\n",
       "0  A30TL5EWN6DFXT  120401325X  ...     1400630400  05 21, 2014\n",
       "1   ASY55RVNIL0UD  120401325X  ...     1389657600  01 14, 2014\n",
       "2  A2TMXE2AFO7ONB  120401325X  ...     1403740800  06 26, 2014\n",
       "3   AWJ0WZQYMYFQ4  120401325X  ...     1382313600  10 21, 2013\n",
       "4   ATX7CZYFXI1KW  120401325X  ...     1359849600   02 3, 2013\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"E:/DS/Datasets/Cell_Phones_and_Accessories_5.json\", lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a11ed38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.reviewText[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b063ff3d",
   "metadata": {},
   "source": [
    "#### Simple Preprocessing & Tokenization\n",
    "The first thing to do for any data science task is to clean the data. For NLP, we apply various processing like converting all the words to lower case, trimming spaces, removing punctuations. This is something we will do over here too.\n",
    "\n",
    "Additionally, we can also remove stop words like 'and', 'or', 'is', 'the', 'a', 'an' and convert words to their root forms like 'running' to 'run'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45834fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gensim.utils.simple_preprocess(df.reviewText[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b9c8e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [they, look, good, and, stick, good, just, don...\n",
       "1         [these, stickers, work, like, the, review, say...\n",
       "2         [these, are, awesome, and, make, my, phone, lo...\n",
       "3         [item, arrived, in, great, time, and, was, in,...\n",
       "4         [awesome, stays, on, and, looks, great, can, b...\n",
       "                                ...                        \n",
       "194434    [works, great, just, like, my, original, one, ...\n",
       "194435    [great, product, great, packaging, high, quali...\n",
       "194436    [this, is, great, cable, just, as, good, as, t...\n",
       "194437    [really, like, it, becasue, it, works, well, w...\n",
       "194438    [product, as, described, have, wasted, lot, of...\n",
       "Name: reviewText, Length: 194439, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text = df.reviewText.apply(gensim.utils.simple_preprocess)\n",
    "review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33e0e483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they',\n",
       " 'look',\n",
       " 'good',\n",
       " 'and',\n",
       " 'stick',\n",
       " 'good',\n",
       " 'just',\n",
       " 'don',\n",
       " 'like',\n",
       " 'the',\n",
       " 'rounded',\n",
       " 'shape',\n",
       " 'because',\n",
       " 'was',\n",
       " 'always',\n",
       " 'bumping',\n",
       " 'it',\n",
       " 'and',\n",
       " 'siri',\n",
       " 'kept',\n",
       " 'popping',\n",
       " 'up',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'irritating',\n",
       " 'just',\n",
       " 'won',\n",
       " 'buy',\n",
       " 'product',\n",
       " 'like',\n",
       " 'this',\n",
       " 'again']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddea319",
   "metadata": {},
   "source": [
    "#### Training the Word2Vec Model\n",
    "Train the model for reviews. Use a window of size 10 i.e. 10 words before the present word and 10 words ahead. A sentence with at least 2 words should only be considered, configure this using min_count parameter.\n",
    "\n",
    "Workers define how many CPU threads to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1bc4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0b666ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(review_text, progress_per=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "62798546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194439"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae79d3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "763d27f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61507941, 83868975)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "562132fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"E:/DS/Datasets/word2vec-amazon-cell-accessories-reviews-short.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14c13381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('terrible', 0.6802547574043274),\n",
       " ('shabby', 0.6135326027870178),\n",
       " ('horrible', 0.5993013381958008),\n",
       " ('good', 0.5745214819908142),\n",
       " ('awful', 0.5598459243774414),\n",
       " ('crappy', 0.5416638851165771),\n",
       " ('cheap', 0.5270234942436218),\n",
       " ('okay', 0.5225250720977783),\n",
       " ('funny', 0.5218287706375122),\n",
       " ('legit', 0.5145692825317383)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63170f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4994413"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"cheap\", w2=\"inexpensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05c8ae86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878908"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"great\", w2=\"good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2910baec",
   "metadata": {},
   "source": [
    "##### Tensorflow Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "381d2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25297db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_sales_numbers = [21, 22, -108, 31, -1, 32, 34,31]\n",
    "\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0ef9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1dad88f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "864bc6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n"
     ]
    }
   ],
   "source": [
    "for sales in tf_dataset.take(3):\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cf122f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "31\n",
      "32\n",
      "34\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.filter(lambda x: x>0)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd247055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1512\n",
      "1584\n",
      "2232\n",
      "2304\n",
      "2448\n",
      "2232\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.map(lambda x: x*72)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7679ca77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1584\n",
      "2304\n",
      "2232\n",
      "2232\n",
      "1512\n",
      "2448\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.shuffle(2)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82b13410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1512 2304]\n",
      "[2448 2232]\n",
      "[1584 2232]\n"
     ]
    }
   ],
   "source": [
    "for sales_batch in tf_dataset.batch(2):\n",
    "    print(sales_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cb60004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1584 2232]\n",
      "[1512 2448]\n",
      "[2304 2232]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "\n",
    "tf_dataset = tf_dataset.filter(lambda x: x>0).map(lambda y: y*72).shuffle(2).batch(2)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb0fb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ds = tf.data.Dataset.list_files('E:DS/Datasets/catdog/*/*', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "364799a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(images_ds)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96491c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'E:DS\\\\Datasets\\\\catdog\\\\cat\\\\00tb-cats1-mediumSquareAt3X.jpg'\n",
      "b'E:DS\\\\Datasets\\\\catdog\\\\cat\\\\016f72c5812e1b8f71bdbf19d8c7558b.jpg'\n",
      "b'E:DS\\\\Datasets\\\\catdog\\\\cat\\\\07CAT-STRIPES-mediumSquareAt3X-v2.jpg'\n"
     ]
    }
   ],
   "source": [
    "for file in images_ds.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "beadce76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'E:DS\\\\Datasets\\\\catdog\\\\cat\\\\maxresdefault (2).jpg'\n",
      "b'E:DS\\\\Datasets\\\\catdog\\\\dog\\\\15014.jpg'\n",
      "b'E:DS\\\\Datasets\\\\catdog\\\\dog\\\\golden-retriever-sitting-in-front-of-a-white-background.jpg'\n"
     ]
    }
   ],
   "source": [
    "images_ds = images_ds.shuffle(200)\n",
    "for file in images_ds.take(3):\n",
    "    print(file.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "79e741f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"cat\",\"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7607df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(image_count*0.8)\n",
    "train_ds = images_ds.take(train_size)\n",
    "test_ds = images_ds.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "110e2786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb19e409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c7d0ad9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'are'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s='Hi\\\\are\\\\you'\n",
    "s.split('\\\\')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "175f47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    import os\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84e41954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "    img = tf.io.read_file(file_path) # load the raw data from the file as a string\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [128, 128])\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57f2fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(process_image)\n",
    "test_ds = test_ds.map(process_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c41e4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    return image/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d0e5ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1234b7",
   "metadata": {},
   "source": [
    "#### Optimize tensorflow pipeline performance with prefetch and caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5cb16db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8291c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileDataset(tf.data.Dataset):\n",
    "    def read_file_in_batches(num_samples):\n",
    "        # Opening the file\n",
    "        time.sleep(0.03)\n",
    "\n",
    "        for sample_idx in range(num_samples):\n",
    "            # Reading data (line, record) from the file\n",
    "            time.sleep(0.015)\n",
    "\n",
    "            yield (sample_idx,)\n",
    "\n",
    "    def __new__(cls, num_samples=3):\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            cls.read_file_in_batches,\n",
    "            output_signature = tf.TensorSpec(shape = (1,), dtype = tf.int64),\n",
    "            args=(num_samples,)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "80c5177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(dataset, num_epochs=2):\n",
    "    for epoch_num in range(num_epochs):\n",
    "        for sample in dataset:\n",
    "            # Performing a training step\n",
    "            time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67547664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "574 ms ± 34.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "benchmark(FileDataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ddb86cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526 ms ± 38 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "benchmark(FileDataset().prefetch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "87a3a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515 ms ± 91.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "benchmark(FileDataset().prefetch(tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "90eafd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.range(5)\n",
    "dataset = dataset.map(lambda x: x**2)\n",
    "dataset = dataset.cache(\"mycache.txt\")\n",
    "# The first time reading through the data will generate the data using\n",
    "# `range` and `map`.\n",
    "list(dataset.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2712c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapped_function(s):\n",
    "    # Do some hard pre-processing\n",
    "    tf.py_function(lambda: time.sleep(0.03), [], ())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8cf57856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "benchmark(FileDataset().map(mapped_function), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e8a65831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "benchmark(FileDataset().map(mapped_function).cache(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaefcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
